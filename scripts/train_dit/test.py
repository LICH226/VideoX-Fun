#!/usr/bin/env python
# coding=utf-8

import argparse
import os
import sys
import random
import torch
import torch.nn.functional as F
import numpy as np
from functools import partial
from accelerate import Accelerator
from accelerate.utils import set_seed
from torch.utils.data import RandomSampler, DataLoader
from tqdm.auto import tqdm

# ---------------------------------------------------------------------------
# è·¯å¾„ Hack (ç¡®ä¿èƒ½ import videox_fun)
# ---------------------------------------------------------------------------
current_file_path = os.path.abspath(__file__)
project_roots = [os.path.dirname(current_file_path), os.path.dirname(os.path.dirname(current_file_path))]
for project_root in project_roots:
    sys.path.insert(0, project_root) if project_root not in sys.path else None

# å¼•å…¥ä½ çš„ Dataset å’Œ Sampler
from videox_fun.data.tryon_video import TryOnDataset
from videox_fun.data.bucket_sampler import AspectRatioBatchImageVideoSamplerTryOn, ASPECT_RATIO_512

# ---------------------------------------------------------------------------
# 1. æ–°ç‰ˆ Collate Fn (å¤åˆ¶è¿‡æ¥ï¼Œæˆ–è€…ä» train.py import)import torch
import torch.nn.functional as F

def vton_collate_fn(examples, max_res=512):
    """
    åŠŸèƒ½ï¼š
    1. ç©ºé—´ä¸Šï¼šä¿æŒåŸé•¿å®½æ¯”ï¼Œé•¿è¾¹å¼ºåˆ¶ç¼©æ”¾åˆ° max_resï¼Œå¹¶ 32 å¯¹é½ã€‚
    2. æ—¶é—´ä¸Šï¼šä»¥ Batch ä¸­ç¬¬ä¸€ä¸ªæ ·æœ¬çš„å¸§æ•°ä¸ºåŸºå‡†ï¼Œå¼ºåˆ¶å¯¹é½å…¶ä»–æ ·æœ¬ï¼ˆå¤åˆ¶æˆ–è£åˆ‡ï¼‰ã€‚
    """
    # ---------------------------------------------------
    # 1. è®¡ç®—ç›®æ ‡åˆ†è¾¨ç‡ (Spatial)
    # ---------------------------------------------------
    raw_max_h = max([ex["pixel_values"].shape[-2] for ex in examples])
    raw_max_w = max([ex["pixel_values"].shape[-1] for ex in examples])
    
    current_long_side = max(raw_max_h, raw_max_w)
    
    # å¼ºåˆ¶ç¼©æ”¾åˆ° max_res
    scale = max_res / current_long_side
    
    target_h = int(raw_max_h * scale)
    target_w = int(raw_max_w * scale)

    # VAE 32å¯¹é½
    target_h = max(32, round(target_h / 32) * 32)
    target_w = max(32, round(target_w / 32) * 32)

    # ---------------------------------------------------
    # 2. ç¡®å®šç›®æ ‡å¸§æ•° (Temporal)
    # ---------------------------------------------------
    # ä»¥ç¬¬ä¸€ä¸ªæ ·æœ¬ä¸ºåŸºå‡†ã€‚
    # å¦‚æœæ˜¯ Image Stageï¼Œè¿™é‡Œæ˜¯ 1ï¼›å¦‚æœæ˜¯ Video Stageï¼Œè¿™é‡Œæ˜¯ 49
    target_len = examples[0]["pixel_values"].shape[0] 

    # ---------------------------------------------------
    # 3. å¤„ç†æ•°æ®
    # ---------------------------------------------------
    aligned_examples = []
    # éœ€è¦å¤„ç†æ—¶é—´ç»´åº¦çš„ key
    temporal_keys = ["pixel_values", "densepose_pixel_values", "agnostic_pixel_values", "mask_pixel_values"]

    for ex in examples:
        new_ex = {}
        new_ex["data_type"] = ex["data_type"]
        new_ex["text"] = ex["text"]
        
        # è·å–å½“å‰æ ·æœ¬çš„å¸§æ•°
        curr_len = ex["pixel_values"].shape[0]

        for key in temporal_keys:
            if key not in ex: continue
            tensor = ex[key] # Shape: [T, C, H, W]
            
            # --- A. æ—¶é—´ç»´åº¦å¯¹é½ (Temporal Align) ---
            if curr_len < target_len:
                # å¦‚æœå½“å‰çŸ­ (e.g. 1 < 49)ï¼Œé‡å¤å¡«å……
                repeat_times = target_len // curr_len + 1
                tensor = tensor.repeat(repeat_times, 1, 1, 1)[:target_len]
            elif curr_len > target_len:
                # å¦‚æœå½“å‰é•¿ (e.g. 60 > 49)ï¼Œæˆªå–
                tensor = tensor[:target_len]
            
            # --- B. ç©ºé—´ç»´åº¦å¯¹é½ (Spatial Resize) ---
            mode = 'nearest' if 'mask' in key or 'densepose' in key else 'bilinear'
            align_corners = False if mode != 'nearest' else None
            
            # F.interpolate æ¥å— [N, C, H, W]ï¼Œè¿™é‡Œ T ç»´åº¦å……å½“ Nï¼Œæ­£å¥½æ‰¹é‡å¤„ç†æ¯ä¸€å¸§
            if tensor.shape[-2] != target_h or tensor.shape[-1] != target_w:
                tensor = F.interpolate(tensor, size=(target_h, target_w), mode=mode, align_corners=align_corners)
            
            new_ex[key] = tensor

        # --- Cloth å•ç‹¬å¤„ç† (å§‹ç»ˆæ˜¯å•å¸§å›¾åƒï¼Œä¸éœ€è¦æ—¶é—´å¯¹é½) ---
        if "cloth_pixel_values" in ex:
            cloth = ex["cloth_pixel_values"] # [1, C, H, W]
            if cloth.shape[-2] != target_h or cloth.shape[-1] != target_w:
                cloth = F.interpolate(cloth, size=(target_h, target_w), mode='bilinear', align_corners=False)
            new_ex["cloth_pixel_values"] = cloth

        aligned_examples.append(new_ex)

    # 4. Stack
    batch = {
        "pixel_values": torch.stack([ex["pixel_values"] for ex in aligned_examples]),
        "cloth_pixel_values": torch.stack([ex["cloth_pixel_values"] for ex in aligned_examples]),
        "agnostic_pixel_values": torch.stack([ex["agnostic_pixel_values"] for ex in aligned_examples]),
        "mask_pixel_values": torch.stack([ex["mask_pixel_values"] for ex in aligned_examples]),
        "densepose_pixel_values": torch.stack([ex["densepose_pixel_values"] for ex in aligned_examples]),
        "text": [ex["text"] for ex in aligned_examples],
        "data_type": [ex["data_type"] for ex in aligned_examples]
    }
    
    return batch

# ---------------------------------------------------------------------------
# 2. Main Check Logic
# ---------------------------------------------------------------------------


# ---------------------------------------------------------------------------
# 2. Main Check Logic
# ---------------------------------------------------------------------------
def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--train_data_dir", type=str, required=True)
    parser.add_argument("--train_data_meta", type=str, required=True)
    
    parser.add_argument("--filter_type", type=str, default="image", choices=["image", "video"])
    parser.add_argument("--max_res", type=int, default=512)
    
    parser.add_argument("--train_batch_size", type=int, default=1)
    parser.add_argument("--max_check_steps", type=int, default=50, help="æ‰“å°å‰50ä¸ªbatchçœ‹çœ‹")
    parser.add_argument("--seed", type=int, default=42)
    
    args = parser.parse_args()
    return args

def main():
    args = parse_args()
    accelerator = Accelerator()
    if args.seed: set_seed(args.seed)

    if accelerator.is_main_process:
        print(f"\nğŸš€ [Check Start] Mode: {args.filter_type.upper()} | Target Max Res: {args.max_res}")

    # 1. åˆå§‹åŒ– Dataset
    dataset = TryOnDataset(
        ann_path=args.train_data_meta,
        data_root=args.train_data_dir,
        # è¿™äº›å‚æ•°å…¶å®éƒ½ä¸é‡è¦äº†ï¼Œå› ä¸ºéƒ½åœ¨ Collate é‡Œå¤„ç†ï¼Œä½†ä¸ºäº†å…¼å®¹æ€§ä¼ è¿›å»
        video_sample_n_frames=49, 
        filter_type=args.filter_type 
    )

    # 2. Sampler
    batch_sampler = AspectRatioBatchImageVideoSamplerTryOn(
        sampler=RandomSampler(dataset),
        dataset=dataset,
        batch_size=args.train_batch_size,
        aspect_ratios=ASPECT_RATIO_512,
        drop_last=True
    )

    # 3. Collate (ç»‘å®š max_res)
    collate_fn = partial(vton_collate_fn, max_res=args.max_res)

    # 4. DataLoader
    dataloader = DataLoader(
        dataset, 
        batch_sampler=batch_sampler, 
        collate_fn=collate_fn,
        num_workers=4
    )
    dataloader = accelerator.prepare(dataloader)

    # 5. Check Loop
    iterator = iter(dataloader)
    
    # ä½¿ç”¨ tqdmï¼Œä½†åœ¨å¾ªç¯å†…éƒ¨å¼ºåˆ¶ print
    for step in range(args.max_check_steps):
        try:
            batch = next(iterator)
        except StopIteration:
            break

        # è·å–å½“å‰å¡ä¿¡æ¯
        local_tensor = batch['pixel_values']
        local_type = batch['data_type'][0]
        
        B, T, C, H, W = local_tensor.shape
        type_flag = 1.0 if local_type == 'video' else 0.0
        
        # æ„é€ ä¿¡æ¯å‘é‡: [B, T, H, W, Type]
        info_vec = torch.tensor([float(B), float(T), float(H), float(W), type_flag], device=accelerator.device).unsqueeze(0)
        
        # é›†åˆé€šä¿¡ Gather
        gathered = accelerator.gather(info_vec) # [Num_GPU, 5]

        if accelerator.is_main_process:
            first = gathered[0]
            
            # --- æ ¡éªŒä¸€è‡´æ€§ ---
            is_valid = True
            for i in range(1, gathered.shape[0]):
                if not torch.equal(first, gathered[i]):
                    is_valid = False
                    print(f"âŒ [FAIL] Step {step}: Mismatch GPU 0 vs GPU {i}")
                    print(f"   GPU 0: {first.tolist()}")
                    print(f"   GPU {i}: {gathered[i].tolist()}")
                    break
            
            # --- æ‰“å°å½¢çŠ¶ ---
            if is_valid:
                b_val = int(first[0].item())
                t_val = int(first[1].item())
                h_val = int(first[2].item())
                w_val = int(first[3].item())
                
                # æ‰“å°æ ¼å¼: Step | [B, C, T, H, W]
                print(f"Step {step:03d} | Shape: [{b_val}, 3, {t_val}, {h_val}, {w_val}] | Res: {h_val}x{w_val}")

    print("ğŸ‰ Check Finished.")

if __name__ == "__main__":
    main()