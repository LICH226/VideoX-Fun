import argparse
import os
import sys
import time
from tqdm import tqdm
from torch.utils.data import DataLoader
import torch

# å‡è®¾ä½ çš„ä»£ç ç»“æ„å¦‚ä¸‹ï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ import
# å¿…é¡»ç¡®ä¿èƒ½å¼•ç”¨åˆ°ä½ çš„ TryOnDataset ç±»
sys.path.append(".") 
from videox_fun.data.tryon_video import TryOnDataset 

def validate_dataset(args):
    print(f"ğŸ” Starting dataset validation...")
    print(f"ğŸ“‚ Data Root: {args.train_data_dir}")
    print(f"ğŸ“„ Metadata: {args.train_data_meta}")

    # 1. åˆå§‹åŒ– Dataset
    # ä½¿ç”¨å’Œè®­ç»ƒè„šæœ¬ä¸€è‡´çš„å‚æ•°ï¼Œç¡®ä¿æµ‹è¯•ç¯å¢ƒä¸€è‡´
    dataset = TryOnDataset(
        ann_path=args.train_data_meta,
        data_root=args.train_data_dir,
        video_sample_size=args.video_sample_size,
        video_sample_stride=args.video_sample_stride,
        video_sample_n_frames=args.video_sample_n_frames,
        image_sample_size=args.image_sample_size,
        video_repeat=0, # éªŒè¯æ—¶ä¸é‡å¤è§†é¢‘ï¼Œè·‘ä¸€éå³å¯
        text_drop_ratio=0.0
    )

    # 2. å®šä¹‰ä¸€ä¸ªç®€å•çš„ Collate Fn (åªè¦èƒ½å †å å°±è¡Œï¼Œç”šè‡³å¯ä»¥è¿”å› None)
    def fast_collate(batch):
        # æˆ‘ä»¬åªå…³å¿ƒæ˜¯å¦æŠ¥é”™ï¼Œä¸å…³å¿ƒ Tensor å½¢çŠ¶
        return batch

    # 3. åˆå§‹åŒ– DataLoader
    # num_workers å»ºè®®è®¾ç½®é«˜ä¸€ç‚¹ï¼Œå¿«é€Ÿåƒæ»¡ CPU
    dataloader = DataLoader(
        dataset,
        batch_size=1, # é€ä¸ªéªŒè¯ï¼Œæ–¹ä¾¿å®šä½åæ–‡ä»¶
        shuffle=False, # æŒ‰é¡ºåºè¯»ï¼Œæ–¹ä¾¿å¯¹åº”è¡Œå·
        num_workers=args.num_workers,
        collate_fn=fast_collate,
        prefetch_factor=2
    )

    print(f"ğŸ“Š Total samples: {len(dataset)}")
    print(f"ğŸš€ Running with {args.num_workers} workers...")

    start_time = time.time()
    success_count = 0
    error_count = 0
    bad_files = []

    # 4. å¼€å§‹éå†
    # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
    pbar = tqdm(dataloader, total=len(dataset), unit="samples")
    
    for i, batch in enumerate(pbar):
        # åœ¨ DataLoader å†…éƒ¨ï¼Œå¦‚æœæœ‰é”™è¯¯ï¼Œä½ çš„ Dataset.__getitem__ é‡Œçš„ try...except 
        # å¯èƒ½ä¼šæ•è·å¹¶é‡è¯•ã€‚ä¸ºäº†éªŒè¯ï¼Œæˆ‘ä»¬ä¸ä»…è¦çœ‹èƒ½ä¸èƒ½è·‘é€šï¼Œ
        # è¿˜è¦çœ‹ä½ çš„ Dataset ç±»æ˜¯å¦åœ¨é‡åˆ°åæ–‡ä»¶æ—¶æ‰“å°äº† Logã€‚
        
        # è¿™é‡Œçš„ batch æ˜¯ __getitem__ çš„è¿”å›å€¼
        # å¦‚æœä½ çš„ Dataset åœ¨å‡ºé”™æ—¶ raise Errorï¼Œè¿™é‡Œå°±ä¼šæ•è·ä¸åˆ°ï¼ˆè¿›ç¨‹ä¼šæŒ‚ï¼‰
        # æ‰€ä»¥ç¡®ä¿ä½ çš„ Dataset.__getitem__ å†™å¾—è¶³å¤Ÿå¥å£®
        
        # å¦‚æœèƒ½è¿è¡Œåˆ°è¿™é‡Œï¼Œè¯´æ˜è¯»å–æˆåŠŸï¼ˆæˆ–è€…è¢« Dataset å†…éƒ¨çš„ try-catch å¤„ç†äº†ï¼‰
        success_count += 1
        
        # å¯ä»¥åœ¨è¿™é‡Œæ‰“å°å½“å‰æ–‡ä»¶åï¼ˆå¦‚æœ Dataset è¿”å›äº† pathï¼‰
        # print(batch[0]['file_name']) 

    total_time = time.time() - start_time
    print("\n" + "="*50)
    print(f"âœ… Validation Finished in {total_time:.2f}s")
    print(f"ğŸŸ¢ Successful samples: {success_count}")
    print(f"ğŸ”´ Failed samples (caught by loader): {len(dataset) - success_count}")
    print("="*50)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    # æ ¹æ®ä½ çš„è®­ç»ƒè„šæœ¬å‚æ•°ä¿®æ”¹é»˜è®¤å€¼
    parser.add_argument("--train_data_dir", type=str, required=True)
    parser.add_argument("--train_data_meta", type=str, required=True)
    parser.add_argument("--video_sample_size", type=int, default=512)
    parser.add_argument("--image_sample_size", type=int, default=512)
    parser.add_argument("--video_sample_n_frames", type=int, default=49)
    parser.add_argument("--video_sample_stride", type=int, default=1)
    parser.add_argument("--num_workers", type=int, default=16) # å¼€å¤§ä¸€ç‚¹åŠ é€Ÿ
    
    args = parser.parse_args()
    
    validate_dataset(args)